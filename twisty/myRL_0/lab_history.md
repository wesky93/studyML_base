# 실험 기록 관리
여기에 실험을 할때마다 변경사항과 실험로그 이름을 기록해둔다.

# 양식

---
## lab_날짜
### 게임 규칙 변경사항
- 기본 게임규칙 적용
- 기본 보상 = 0
- 최종 완성 보상 = 100

### 모델 변경사항
-

### 결과
-

### 기타
-
---

# 기록

---
## lab1_20170212
### 게임 규칙 변경사항
- 기본 보상 = 0
- 최종 완성 보상 = 100

### 모델 변경사항
- cost : reduce_mean -> reduce_sum 으로 변경

### 결과
- 제대로 학습 않됨

### 기타
- 최소 학습 방식을 바꿔서 다시 시도해보자 1000번만으로는 제대로 학습안될 가능성이 높음
---


---
## lab2_20170214
### 게임 규칙 변경사항
- 이전과 동일

### 모델 변경사항
- 최소 학습 횟수를 1000 -> 100000 으로 변경
- 랜덤확률이 가감되는 크기를 동적으로 변경하도록 함

### 결과
- 초반에 랜덤값을 많이 잡아주니 확실히 이후 cost가 lab1대비 많이 낮춰짐
- 하지만 최종 점수에는 아직 큰 차이가 없음

### 기타
- 일단 최종 점수도 텐서보드에서 볼수 있도록 방법을 강구해봐야 할듯함
-
---

---
## lab3_20170216
### 게임 규칙 변경사항
- 이전과 동일

### 모델 변경사항
- 보상,성공확률,회전횟수를 텐서보드에 기록하도록 함
- 모델에 텐서보드를 위한 그룹 작업을 해
- 감마 값을 0.99 -> 0.5로 변경

### 결과
- cost는 낮아졌으나 보상은 차도가 없다.

### 기타
- 더이상 학습은 무의미 해보이므로 일단 스크램 횟수를 5회로 낮추어 실험을 해야 할듯 하다.
---

---
## lab4_20170216
### 게임 규칙 변경사항
- 스크램크기를 10 -> 5 로 변경

### 모델 변경사항
- 감마 값을 다시 원상복귀(0.5 -> 0.99)


### 결과
- 게임이 쉬워지니 조금더 쉽게 보상을 얻으며 확실히 보상이 상승하는것을 확인함
- 다만 최종 완성으로 가기 보다 중간 보상만을 취득하여 고득점을 달성하려는 문제가 있음

### 기타
- 해결방안은 2가지 일듯 하다. 하나는 보상 방식을 최종 단계에서만 습득하게 하거나 좀더 장기간의 결과로 점수를 얻게 하는 것이다.
- 일단 중간 보상의 부여하는것을 유지하되 규칙 혹은 모델을 변경함으로써 추가적인 학습이 이뤄지게 해야 할듯 싶다.
- 다음 실험을 하기 전에 먼저 메모리 학습을 구현한뒤 실험을 하는 것이 좋을듯 싶다. 어찌됬던 랜덤한 학습이 결과에 좋은 영향을 미치는것은 사실인것 같으니.
---

